import torch
from core.status import status_manager


def load_waifu2x(
    model_type="art_scan",
    method="noise_scale",
    noise_level=3,
    scale=2,
    tile_size=64,
    batch_size=4,
    device_ids=None,   # auto detect náº¿u None
    amp=True,
    source="github",
    repo="nagadomi/nunif",
):
    """
    Load model Waifu2x vá»›i tá»± Ä‘á»™ng phÃ¡t hiá»‡n thiáº¿t bá»‹ (GPU / CPU).
    """
    try:
        # ------------------------------------------------
        # ğŸ” Tá»± Ä‘á»™ng phÃ¡t hiá»‡n thiáº¿t bá»‹
        # ------------------------------------------------
        if device_ids is None:
            if torch.cuda.is_available():
                device_ids = [0]
                device_name = torch.cuda.get_device_name(0)
                status_manager.add(f"ğŸ’ª PhÃ¡t hiá»‡n GPU: {device_name}")
            else:
                device_ids = [-1]
                status_manager.add("âš™ï¸ KhÃ´ng cÃ³ GPU â€” sá»­ dá»¥ng CPU")

        # ------------------------------------------------
        # ğŸš€ Load model
        # ------------------------------------------------
        status_manager.add("ğŸ”„ Äang load model Waifu2x...")

        upscaler = torch.hub.load(
            repo,
            'waifu2x',
            source=source,
            model_type=model_type,
            method=method,
            noise_level=noise_level,
            scale=scale,
            tile_size=tile_size,
            batch_size=batch_size,
            device_ids=device_ids,
            amp=amp if torch.cuda.is_available() else False,  # táº¯t amp náº¿u khÃ´ng cÃ³ GPU
        )

        status_manager.add("âœ… Load model Waifu2x thÃ nh cÃ´ng")
        return upscaler

    except Exception as e:
        status_manager.add(f"âŒ Lá»—i load model Waifu2x: {e}")
        raise


# ==========================================================
# ğŸ”§ TEST TRá»°C TIáº¾P FILE NÃ€Y
# ==========================================================
if __name__ == "__main__":
    status_manager.add("ğŸš€ Test load Waifu2x model báº¯t Ä‘áº§u...")
    try:
        upscaler = load_waifu2x()
        status_manager.add("ğŸ‰ Model load thÃ nh cÃ´ng (test)")
        # Báº¡n cÃ³ thá»ƒ test thÃªm vá»›i áº£nh:
        # img_path = "sample.png"
        # output = upscaler.process(img_path)
        # output.save("output_upscaled.png")
        # status_manager.add("ğŸ“¸ áº¢nh káº¿t quáº£: output_upscaled.png")
    except Exception as e:
        status_manager.add(f"âŒ Lá»—i khi test load model: {e}")
